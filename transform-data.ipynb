{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a67aafe9-c092-4f90-899c-17bc5033da46",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Creating Dimension and Fact Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b018e6c-c187-42e3-9c88-25c090923b8f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Station Dimension Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fce152f8-50d2-4ee5-9e08-3a9ecbd9ef8a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load the staging stations table\n",
    "stations = spark.table(\"shplc_db.default.staging_stations\")\n",
    "\n",
    "# Drop the existing dim_station table if it exists\n",
    "spark.sql(\"DROP TABLE IF EXISTS shplc_db.default.dim_station\")\n",
    "\n",
    "# Select unique stations and save them to the dim_station table\n",
    "stations.dropDuplicates([\"station_id\"]) \\\n",
    "        .select('station_id', 'name', 'latitude', 'longitude') \\\n",
    "        .write.format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .saveAsTable(\"shplc_db.default.dim_station\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "946a435a-4680-4803-9345-10ae34363e6b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Rider Dimension Table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b7e5c67-9fb0-48e5-ac1c-0c21ec2f2b65",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the staging stations table\n",
    "riders = spark.table(\"shplc_db.default.staging_riders\")\n",
    "\n",
    "# Drop the existing dim_station table if it exists\n",
    "spark.sql(\"DROP TABLE IF EXISTS shplc_db.default.dim_rider\")\n",
    "\n",
    "# Select unique stations and save them to the dim_station table\n",
    "riders.dropDuplicates([\"rider_id\"]) \\\n",
    "        .select('rider_id', 'first_name', 'last_name', 'address', 'birthday', 'start_date', 'end_date', 'is_member') \\\n",
    "        .write.format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .saveAsTable(\"shplc_db.default.dim_rider\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "572495b1-79b7-4edf-b672-153b8e9ecdc5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Date Dimension Table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c83b4aaf-08d3-4f1b-9bb6-2893c6ff4ad8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lit, sequence, explode, year, quarter, month, dayofweek, dayofmonth, date_format\n",
    "from pyspark.sql.types import DateType\n",
    "\n",
    "# Load trips data\n",
    "df_trips = spark.read.format(\"delta\").load('/delta/trips')\n",
    "df_trips.createOrReplaceTempView(\"trips_table\")\n",
    "\n",
    "# Get the min and max trip dates\n",
    "min_date = df_trips.agg({\"started_at\": \"min\"}).collect()[0][0]\n",
    "max_date = df_trips.agg({\"started_at\": \"max\"}).collect()[0][0]\n",
    "\n",
    "# Create a date range\n",
    "date_range = spark.createDataFrame([(min_date, max_date)], [\"start\", \"end\"]) \\\n",
    "    .select(explode(sequence(col(\"start\"), col(\"end\"))).alias(\"date\"))\n",
    "\n",
    "# Add additional date fields\n",
    "date_dim = date_range.withColumn(\"formatted_date\", date_format(col(\"date\"), \"yyyy-MM-dd\")) \\\n",
    "    .withColumn(\"date_id\", col(\"formatted_date\").cast(\"string\")) \\\n",
    "    .withColumn(\"year\", year(col(\"date\"))) \\\n",
    "    .withColumn(\"quarter\", quarter(col(\"date\"))) \\\n",
    "    .withColumn(\"month\", month(col(\"date\"))) \\\n",
    "    .withColumn(\"day_of_week\", dayofweek(col(\"date\"))) \\\n",
    "    .withColumn(\"day_of_month\", dayofmonth(col(\"date\")))\n",
    "\n",
    "# Save the date dimension table\n",
    "date_dim.write.format(\"delta\")\\\n",
    "        .mode(\"overwrite\")\\\n",
    "        .saveAsTable(\"shplc_db.default.dim_date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6b4c6d63-aed8-4b72-bdb0-eb4d88fdacc4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Payments Fact Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbedd4af-c8d1-47f8-b865-cce12fdf815b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the staging stations table\n",
    "payments = spark.table(\"shplc_db.default.staging_payments\")\n",
    "\n",
    "# Drop the existing fact_payment table if it exists\n",
    "spark.sql(\"DROP TABLE IF EXISTS shplc_db.default.fact_payment\")\n",
    "\n",
    "# Select unique stations and save them to the fact_payment table\n",
    "payments = payments.join(spark.table(\"shplc_db.default.dim_date\").alias(\"d\"), \n",
    "                          payments.date.cast(\"string\") == col(\"d.date_id\")) \\\n",
    "                  .join(spark.table(\"shplc_db.default.dim_rider\").alias(\"r\"), \n",
    "                          payments.rider_id == col(\"r.rider_id\")) \\\n",
    "                  .select('payment_id', 'amount', 'r.rider_id', 'd.date_id') \\\n",
    "                  .dropDuplicates([\"payment_id\"]) \\\n",
    "                  .write.format(\"delta\") \\\n",
    "                  .mode(\"overwrite\") \\\n",
    "                  .saveAsTable(\"shplc_db.default.fact_payment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "abcaa4d6-0ea4-4b8d-bcdc-55c604071304",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Trips Fact Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd28a9e5-ff62-4f8b-812f-c53e6eb4d11e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load trips data\n",
    "trips = spark.read.format(\"delta\").load('/delta/trips')\n",
    "trips.createOrReplaceTempView(\"trips_table\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0415ea4-c7ac-4647-8be8-bf08e103db4f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[trip_id: string, rideable_type: string, started_at: timestamp, ended_at: timestamp, start_station_id: string, end_station_id: string, rider_id: int]>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b863b589-7ffa-4a16-bada-dfe59aa8d6fa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load trips data\n",
    "trips = spark.read.format(\"delta\").load('/delta/trips')\n",
    "trips.createOrReplaceTempView(\"trips_table\")\n",
    "\n",
    "# Drop the existing fact_payment table if it exists\n",
    "spark.sql(\"DROP TABLE IF EXISTS shplc_db.default.fact_trips\")\n",
    "\n",
    "# Select unique stations and save them to the fact_payment table\n",
    "trips = trips.alias(\"t\").join(\n",
    "            spark.table(\"shplc_db.default.dim_date\").alias(\"sd\"), \n",
    "            col(\"t.started_at\") == col(\"sd.date\")\n",
    "        ).join(\n",
    "            spark.table(\"shplc_db.default.dim_date\").alias(\"ed\"), \n",
    "            col(\"t.ended_at\") == col(\"ed.date\")  \n",
    "        ).join(\n",
    "            spark.table(\"shplc_db.default.dim_rider\").alias(\"r\"), \n",
    "            col(\"t.rider_id\") == col(\"r.rider_id\")\n",
    "        ).select(\n",
    "            'trip_id', \n",
    "            'r.rider_id', \n",
    "            'start_station_id', \n",
    "            'end_station_id', \n",
    "            col('sd.date_id').alias('start_time_id'), \n",
    "            col('ed.date_id').alias('end_time_id'), \n",
    "            'rideable_type', \n",
    "            (col('t.ended_at').cast(\"long\") - col('t.started_at').cast(\"long\")).alias('duration'), \n",
    "            (year(col('t.started_at')) - year(col('r.birthday'))).alias('rider_age')\n",
    "        ).dropDuplicates([\"trip_id\"])\n",
    "\n",
    "trips.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"shplc_db.default.fact_trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c12364d-8d0d-4ad9-9a1d-ec4d4a982467",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "transform-data",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
